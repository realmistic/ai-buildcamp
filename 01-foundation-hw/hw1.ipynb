{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "OpenAI client initialized\n"
                    ]
                }
            ],
            "source": [
                "from openai import OpenAI\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables if not using dirdotenv automatically\n",
                "load_dotenv()\n",
                "\n",
                "openai_client = OpenAI()\n",
                "print(\"OpenAI client initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "from download_books import download_books"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fetching books list from https://raw.githubusercontent.com/alexeygrigorev/ai-engineering-buildcamp-code/main/01-foundation/homework/books.csv...\n",
                        "File thinkpython2.pdf already exists. Skipping download.\n",
                        "File thinkdsp.pdf already exists. Skipping download.\n",
                        "File thinkcomplexity2.pdf already exists. Skipping download.\n",
                        "File thinkjava2.pdf already exists. Skipping download.\n",
                        "File PhysicalModelingInMatlab4.pdf already exists. Skipping download.\n",
                        "File thinkos.pdf already exists. Skipping download.\n",
                        "File Think-C.pdf already exists. Skipping download.\n"
                    ]
                }
            ],
            "source": [
                "# Run the download function\n",
                "download_books()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Skipping thinkcomplexity2.pdf, thinkcomplexity2.md already exists.\n",
                        "Skipping thinkpython2.pdf, thinkpython2.md already exists.\n",
                        "Skipping PhysicalModelingInMatlab4.pdf, PhysicalModelingInMatlab4.md already exists.\n",
                        "Skipping thinkjava2.pdf, thinkjava2.md already exists.\n",
                        "Skipping thinkdsp.pdf, thinkdsp.md already exists.\n",
                        "Skipping thinkos.pdf, thinkos.md already exists.\n",
                        "Skipping Think-C.pdf, Think-C.md already exists.\n",
                        "\n",
                        "Line count for Think Python 2e (books_text/thinkpython2.md): 16268\n"
                    ]
                }
            ],
            "source": [
                "# Q1 answer: 16268 lines\n",
                "\n",
                "# Import extraction logic from external module\n",
                "from convert_books import convert_books_to_markdown\n",
                "\n",
                "# Run the conversion\n",
                "convert_books_to_markdown()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of chunks for PhysicalModelingInMatlab4: 106\n",
                        "Number of chunks for Think-C: 109\n",
                        "Number of chunks for thinkcomplexity2: 130\n",
                        "Number of chunks for thinkdsp: 86\n",
                        "Number of chunks for thinkjava2: 216\n",
                        "Number of chunks for thinkos: 62\n",
                        "Number of chunks for thinkpython2: 214\n",
                        "\n",
                        "Total chunks collected: 923\n"
                    ]
                }
            ],
            "source": [
                "from chunk_books import get_chunks\n",
                "from pathlib import Path\n",
                "\n",
                "# Get all markdown files\n",
                "book_files = sorted(Path(\"books_text\").glob(\"*.md\"))\n",
                "\n",
                "# Collect all chunks from all books\n",
                "all_chunks = []\n",
                "\n",
                "for book_file in book_files:\n",
                "    try:\n",
                "        chunks = get_chunks(book_file.name)\n",
                "        n_chunks = len(chunks)\n",
                "        print(f\"Number of chunks for {book_file.stem}: {n_chunks}\")\n",
                "        all_chunks.extend(chunks)\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {book_file.name}: {e}\")\n",
                "\n",
                "print(f\"\\nTotal chunks collected: {len(all_chunks)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Prepared 923 documents for indexing\n"
                    ]
                }
            ],
            "source": [
                "# Q2 answer: 214 chunks for Think Python\n",
                "\n",
                "def prepare_documents(chunks):\n",
                "    \"\"\"\n",
                "    Prepares chunks for indexing by converting the list content to strings.\n",
                "    Each chunk has a 'content' field that is a list of strings.\n",
                "    We need to join them into a single string.\n",
                "    \"\"\"\n",
                "    documents = []\n",
                "    \n",
                "    for chunk in chunks:\n",
                "        # Join the content list into a single string\n",
                "        content_str = \"\\n\".join(chunk[\"content\"])\n",
                "        \n",
                "        doc = {\n",
                "            \"content\": content_str,\n",
                "            \"source\": chunk[\"source\"]\n",
                "        }\n",
                "        documents.append(doc)\n",
                "    \n",
                "    return documents\n",
                "\n",
                "# Prepare all documents\n",
                "documents = prepare_documents(all_chunks)\n",
                "print(f\"Prepared {len(documents)} documents for indexing\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Q3 answer: Indexed 923 documents (chunks)\n"
                    ]
                }
            ],
            "source": [
                "from minsearch import Index\n",
                "\n",
                "# Create and fit the index\n",
                "index = Index(\n",
                "    text_fields=[\"content\"],\n",
                "    keyword_fields=[\"source\"]\n",
                ")\n",
                "\n",
                "index.fit(documents)\n",
                "\n",
                "print(f\"\\nQ3 answer: Indexed {len(documents)} documents (chunks)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Top search result:\n",
                        "Source: /Users/realmistic/Documents/ai-buildcamp/01-foundation-hw/books_text/thinkpython2.md\n",
                        "\n",
                        "Content preview (first 200 chars):\n",
                        "when you are comfortable with Python, I’ll make suggestions for installing Python on your\n",
                        "computer.\n",
                        "There are a number of web pages you can use to run Python. If you already have a fa-\n",
                        "vorite, go ahea...\n",
                        "\n",
                        "==================================================\n",
                        "All 5 results:\n",
                        "\n",
                        "1. Source: /Users/realmistic/Documents/ai-buildcamp/01-foundation-hw/books_text/thinkpython2.md\n",
                        "   Content preview: when you are comfortable with Python, I’ll make suggestions for installing Python on your\n",
                        "computer.\n",
                        "...\n",
                        "\n",
                        "2. Source: /Users/realmistic/Documents/ai-buildcamp/01-foundation-hw/books_text/thinkpython2.md\n",
                        "   Content preview: .\n",
                        ".\n",
                        ".\n",
                        ".\n",
                        ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\n",
                        ". . . . . . . . . . . ...\n",
                        "\n",
                        "3. Source: /Users/realmistic/Documents/ai-buildcamp/01-foundation-hw/books_text/thinkpython2.md\n",
                        "   Content preview: cording to Larry Greenﬁeld, “One of Linus’s earlier projects was a program that would\n",
                        "switch between...\n",
                        "\n",
                        "4. Source: /Users/realmistic/Documents/ai-buildcamp/01-foundation-hw/books_text/thinkjava2.md\n",
                        "   Content preview: Chapter 8 Recursive Methods\n",
                        "What happens if we invoke countdown(3) from main?\n",
                        "The execution of count...\n",
                        "\n",
                        "5. Source: /Users/realmistic/Documents/ai-buildcamp/01-foundation-hw/books_text/thinkdsp.md\n",
                        "   Content preview: Think DSP\n",
                        "Digital Signal Processing in Python\n",
                        "Version 1.1.4\n",
                        "Think DSP\n",
                        "Digital Signal Processing in P...\n"
                    ]
                }
            ],
            "source": [
                "# Q4: Search for 'python function definition'\n",
                "results = index.search(\"python function definition\", num_results=5)\n",
                "\n",
                "print(\"Top search result:\")\n",
                "print(f\"Source: {results[0]['source']}\")\n",
                "print(f\"\\nContent preview (first 200 chars):\\n{results[0]['content'][:200]}...\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"All 5 results:\")\n",
                "for i, result in enumerate(results, 1):\n",
                "    print(f\"\\n{i}. Source: {result['source']}\")\n",
                "    print(f\"   Content preview: {result['content'][:100]}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RAG Response:\n",
                        "================================================================================\n",
                        "In Python, a function is defined using the `def` keyword, followed by the function name and parentheses containing any parameters. The body of the function, which contains the code to be executed, is indented below the definition line. Here's the basic structure of a function definition:\n",
                        "\n",
                        "```python\n",
                        "def function_name(parameters):\n",
                        "    # Body of the function\n",
                        "    # Perform operations\n",
                        "    return value  # Optional\n",
                        "```\n",
                        "\n",
                        "Here's an example of a simple function that adds two numbers:\n",
                        "\n",
                        "```python\n",
                        "def add_numbers(a, b):\n",
                        "    sum = a + b\n",
                        "    return sum\n",
                        "```\n",
                        "\n",
                        "You can call this function using its name and passing the required arguments:\n",
                        "\n",
                        "```python\n",
                        "result = add_numbers(5, 3)  # result will be 8\n",
                        "```\n",
                        "\n",
                        "Remember that functions can return a value using the `return` statement, and they can also accept parameters, which are values you provide when you call the function.\n",
                        "================================================================================\n",
                        "\n",
                        "Token Usage:\n",
                        "  Input tokens: 6991\n",
                        "  Output tokens: 189\n",
                        "  Total tokens: 7180\n",
                        "\n",
                        "Q5 answer: 6991 input tokens\n"
                    ]
                }
            ],
            "source": [
                "# Q5: Full RAG Pipeline\n",
                "import json\n",
                "\n",
                "instructions = \"\"\"\n",
                "You're a course assistant, your task is to answer the QUESTION from the\n",
                "course students using the provided CONTEXT\n",
                "\"\"\"\n",
                "\n",
                "prompt_template = \"\"\"\n",
                "<QUESTION>\n",
                "{question}\n",
                "</QUESTION>\n",
                "\n",
                "<CONTEXT>\n",
                "{context}\n",
                "</CONTEXT>\n",
                "\"\"\".strip()\n",
                "\n",
                "def build_prompt(question, search_results):\n",
                "    context = json.dumps(search_results, indent=2)\n",
                "    prompt = prompt_template.format(\n",
                "        question=question,\n",
                "        context=context\n",
                "    ).strip()\n",
                "    return prompt\n",
                "\n",
                "def search(question):\n",
                "    return index.search(question, num_results=5)\n",
                "\n",
                "def llm(user_prompt, instructions, model='gpt-4o-mini'):\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": instructions},\n",
                "        {\"role\": \"user\", \"content\": user_prompt}\n",
                "    ]\n",
                "\n",
                "    response = openai_client.chat.completions.create(\n",
                "        model=model,\n",
                "        messages=messages\n",
                "    )\n",
                "    \n",
                "    # Extract token counts\n",
                "    input_tokens = response.usage.prompt_tokens\n",
                "    output_tokens = response.usage.completion_tokens\n",
                "    total_tokens = response.usage.total_tokens\n",
                "    \n",
                "    answer = response.choices[0].message.content\n",
                "    \n",
                "    return answer, input_tokens, output_tokens, total_tokens\n",
                "\n",
                "def rag(query):\n",
                "    search_results = search(query)\n",
                "    prompt = build_prompt(query, search_results)\n",
                "    answer, input_tokens, output_tokens, total_tokens = llm(prompt, instructions)\n",
                "    return answer, input_tokens, output_tokens, total_tokens\n",
                "\n",
                "# Run RAG for \"python function definition\"\n",
                "query = \"python function definition\"\n",
                "answer, input_tokens, output_tokens, total_tokens = rag(query)\n",
                "\n",
                "print(\"RAG Response:\")\n",
                "print(\"=\"*80)\n",
                "print(answer)\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nToken Usage:\")\n",
                "print(f\"  Input tokens: {input_tokens}\")\n",
                "print(f\"  Output tokens: {output_tokens}\")\n",
                "print(f\"  Total tokens: {total_tokens}\")\n",
                "print(f\"\\nQ5 answer: {input_tokens} input tokens\")\n",
                "\n",
                "# Store for comparison in Q6\n",
                "q5_input_tokens = input_tokens"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Structured RAG Response:\n",
                        "================================================================================\n",
                        "Answer: In Python, a function definition is a special statement that defines a new function, specifying its name, parameters, and the block of code that makes up its body. Here’s a simple example of a function definition:\n",
                        "\n",
                        "```python\n",
                        "def greet(name):\n",
                        "    print(f'Hello, {name}!')\n",
                        "```\n",
                        "\n",
                        "### Breakdown of the Example:\n",
                        "- `def`: This keyword indicates the start of a function definition.\n",
                        "- `greet`: This is the name of the function. You can call this function by using its name later in your code.\n",
                        "- `(name)`: This is the parameter list. In this case, `name` is a parameter that the function accepts when called. \n",
                        "- The indented lines under the `def` statement form the body of the function. This code runs whenever the function is called.\n",
                        "\n",
                        "### Calling the Function:\n",
                        "You can call the function like this:\n",
                        "```python\n",
                        "greet('Alice')  # Output: Hello, Alice!\n",
                        "```\n",
                        "\n",
                        "Functions can also return values, accept multiple parameters, and include default values. The function definition is essential for structuring your code into reusable components, which helps in maintaining and managing complex programs efficiently.\n",
                        "\n",
                        "Found Answer: True\n",
                        "Confidence: 0.9\n",
                        "Confidence Explanation: The answer provides a clear explanation and example of Python function definitions, which aligns with the context of programming in Python from the provided material. Though not directly sourced, similar concepts are covered comprehensively in the context.\n",
                        "Answer Type: how-to\n",
                        "\n",
                        "Follow-up Questions:\n",
                        "  1. What are function parameters?\n",
                        "  2. How do I return a value from a function?\n",
                        "  3. Can functions have default parameters in Python?\n",
                        "================================================================================\n",
                        "\n",
                        "Token Usage (Structured):\n",
                        "  Input tokens: 7181\n",
                        "  Output tokens: 351\n",
                        "  Total tokens: 7532\n",
                        "\n",
                        "Comparison with Q5:\n",
                        "  Q5 input tokens: 6991\n",
                        "  Q6 input tokens: 7181\n",
                        "  Difference: 190 tokens\n",
                        "\n",
                        "Q6 answer: 190 more input tokens\n"
                    ]
                }
            ],
            "source": [
                "# Q6: Structured Output with Pydantic\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import Literal\n",
                "\n",
                "class RAGResponse(BaseModel):\n",
                "    answer: str = Field(description=\"The main answer to the user's question in markdown\")\n",
                "    found_answer: bool = Field(description=\"True if relevant information was found in the documentation\")\n",
                "    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n",
                "    confidence_explanation: str = Field(description=\"Explanation about the confidence level\")\n",
                "    answer_type: Literal[\"how-to\", \"explanation\", \"troubleshooting\", \"comparison\", \"reference\"] = Field(description=\"The category of the answer\")\n",
                "    followup_questions: list[str] = Field(description=\"Suggested follow-up questions\")\n",
                "\n",
                "def llm_structured(user_prompt, instructions, model='gpt-4o-mini'):\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": instructions},\n",
                "        {\"role\": \"user\", \"content\": user_prompt}\n",
                "    ]\n",
                "\n",
                "    response = openai_client.beta.chat.completions.parse(\n",
                "        model=model,\n",
                "        messages=messages,\n",
                "        response_format=RAGResponse\n",
                "    )\n",
                "    \n",
                "    # Extract token counts\n",
                "    input_tokens = response.usage.prompt_tokens\n",
                "    output_tokens = response.usage.completion_tokens\n",
                "    total_tokens = response.usage.total_tokens\n",
                "    \n",
                "    # Get the parsed response\n",
                "    parsed_response = response.choices[0].message.parsed\n",
                "    \n",
                "    return parsed_response, input_tokens, output_tokens, total_tokens\n",
                "\n",
                "def rag_structured(query):\n",
                "    search_results = search(query)\n",
                "    prompt = build_prompt(query, search_results)\n",
                "    response, input_tokens, output_tokens, total_tokens = llm_structured(prompt, instructions)\n",
                "    return response, input_tokens, output_tokens, total_tokens\n",
                "\n",
                "# Run structured RAG for \"python function definition\"\n",
                "query = \"python function definition\"\n",
                "structured_response, structured_input_tokens, structured_output_tokens, structured_total_tokens = rag_structured(query)\n",
                "\n",
                "print(\"Structured RAG Response:\")\n",
                "print(\"=\"*80)\n",
                "print(f\"Answer: {structured_response.answer}\")\n",
                "print(f\"\\nFound Answer: {structured_response.found_answer}\")\n",
                "print(f\"Confidence: {structured_response.confidence}\")\n",
                "print(f\"Confidence Explanation: {structured_response.confidence_explanation}\")\n",
                "print(f\"Answer Type: {structured_response.answer_type}\")\n",
                "print(f\"\\nFollow-up Questions:\")\n",
                "for i, q in enumerate(structured_response.followup_questions, 1):\n",
                "    print(f\"  {i}. {q}\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "print(f\"\\nToken Usage (Structured):\")\n",
                "print(f\"  Input tokens: {structured_input_tokens}\")\n",
                "print(f\"  Output tokens: {structured_output_tokens}\")\n",
                "print(f\"  Total tokens: {structured_total_tokens}\")\n",
                "\n",
                "# Compare with Q5\n",
                "token_difference = structured_input_tokens - q5_input_tokens\n",
                "print(f\"\\nComparison with Q5:\")\n",
                "print(f\"  Q5 input tokens: {q5_input_tokens}\")\n",
                "print(f\"  Q6 input tokens: {structured_input_tokens}\")\n",
                "print(f\"  Difference: {token_difference} tokens\")\n",
                "print(f\"\\nQ6 answer: {token_difference} more input tokens\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
